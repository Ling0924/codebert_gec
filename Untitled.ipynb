{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282094b1-fcd0-462e-80ec-4b80faa69762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Directory Structure and Contents\n",
    "tools/ Contains the core implementation of the seq2edit GEC (Grammar Error Correction) model.\n",
    "data/ This folder stores the data and models required for training and prediction.\n",
    "exp/: Saves the weights and log files generated during model training.\n",
    "modelinput/: Stores the training set, test set, and prediction results.\n",
    "codebert/: Contains the pre-trained CodeBERT model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0315d2-a17b-4454-97b4-64f7a3199783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirements\n",
    "pip install allennlp==1.3.0\n",
    "pip install ltp==4.1.3.post1\n",
    "pip install OpenCC==1.1.2\n",
    "pip install pyarrow\n",
    "pip install python-Levenshtein==0.12.1\n",
    "pip install numpy==1.21.1\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f041ad-2758-4373-b826-bb91bde4372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model type\n",
    "modeltype = 'seq'  # Options: 'seq', 'span', 'word'\n",
    "\n",
    "# Specify the model file path\n",
    "MODEL_FILE = './model/mode_' + modeltype + '.th'\n",
    "\n",
    "# Specify the label file path\n",
    "LABEL_FILE = './data/labels/labels_' + modeltype + '.txt'\n",
    "\n",
    "# Move the model file to the specified directory\n",
    "!cp $MODEL_FILE ./data/exp/Best_code_gec.th\n",
    "\n",
    "# Move the label file to the specified directory\n",
    "!cp $LABEL_FILE ./data/labels/labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7bb87-6444-494b-a59a-11706071c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict model\n",
    "!python predict.py --model_path ./data/exp/Best_code_gec.th \\\n",
    "                  --weights_name ./data/codebert \\\n",
    "                  --vocab_path ./data/labels \\\n",
    "                  --input_file ./data/modelinput/test.src.char \\\n",
    "                  --output_file ./data/modelinput/test.pre.char "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b9b8e-33af-45f4-860e-44c14b21eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the prediction results\n",
    "with open(\"./data/modelinput/test.pre.char\", 'r', encoding='utf-8') as f:\n",
    "    predictionlines = f.readlines()  # Read the prediction results\n",
    "\n",
    "with open(\"./data/modelinput/test.tgt.char\", 'r', encoding='utf-8') as f:\n",
    "    targetlines = f.readlines()  # Read the target (ground truth) results\n",
    "\n",
    "# Print the number of prediction lines and target lines\n",
    "print(len(predictionlines))\n",
    "print(len(targetlines))\n",
    "\n",
    "# Initialize the correct count\n",
    "correct = 0\n",
    "\n",
    "# Compare each prediction with the corresponding target\n",
    "for index in range(len(targetlines)):\n",
    "    if targetlines[index].strip() == predictionlines[index].strip():\n",
    "        correct += 1  # Increment the correct count if they match\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = correct / len(targetlines)\n",
    "print(f'Accuracy: {accuracy:.8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f353f1-4bd5-469e-801e-8c2484720a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# --train_set Training dataset\n",
    "# --dev_set Validation dataset\n",
    "# --model_dir Model output directory\n",
    "# --model_name Model filename\n",
    "# --vocab_path Vocabulary file path\n",
    "# --batch_size Batch size for training\n",
    "# --n_epoch Number of training epochs\n",
    "# --lr Learning rate\n",
    "# --accumulation_size Number of operations before updating gradients\n",
    "# --weights_name CodeBERT encoder weights location\n",
    "# --pretrain_folder Pre-trained model location\n",
    "# --pretrain Pre-trained model name\n",
    "# --seed Random seed\n",
    "!python train.py --train_set ./data/modelinput/train.label \\\n",
    "                --dev_set ./data/modelinput/valid.label \\\n",
    "                --model_dir ./data/exp \\\n",
    "                --model_name Gec_Model.th \\\n",
    "                --vocab_path ./data/labels \\\n",
    "                --batch_size 16\\\n",
    "                --n_epoch 150\\\n",
    "                --lr 1e-5\\\n",
    "                --accumulation_size 4\\\n",
    "                --weights_name ./data/codebert\\\n",
    "                --pretrain_folder ./data/exp \\\n",
    "                --pretrain \"Best_code_gec\"\\\n",
    "                --seed 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
